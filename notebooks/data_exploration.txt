{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb0e1f-2b4e-4d5d-a9ae-11ec9f9f01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Exercise Data Exploration\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook is for exploring and visualizing the exercise data fetched from the APIs.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from IPython.display import Image, display\\n\",\n",
    "    \"import requests\\n\",\n",
    "    \"from PIL import Image as PILImage\\n\",\n",
    "    \"import io\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set plot style\\n\",\n",
    "    \"plt.style.use('fivethirtyeight')\\n\",\n",
    "    \"sns.set_palette('Set2')\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's load and examine the fetched data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load raw data\\n\",\n",
    "    \"raw_data_dir = \\\"data/raw\\\"\\n\",\n",
    "    \"exercisedb_dir = f\\\"{raw_data_dir}/exercisedb\\\"\\n\",\n",
    "    \"wger_dir = f\\\"{raw_data_dir}/wger\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if data exists\\n\",\n",
    "    \"if os.path.exists(f\\\"{exercisedb_dir}/all_exercises.csv\\\"):\\n\",\n",
    "    \"    exercisedb_df = pd.read_csv(f\\\"{exercisedb_dir}/all_exercises.csv\\\")\\n\",\n",
    "    \"    print(f\\\"ExerciseDB data loaded: {len(exercisedb_df)} exercises\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"ExerciseDB data not found. Run the fetch_data.py script first.\\\")\\n\",\n",
    "    \"    exercisedb_df = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"if os.path.exists(f\\\"{wger_dir}/all_exercises.csv\\\"):\\n\",\n",
    "    \"    wger_df = pd.read_csv(f\\\"{wger_dir}/all_exercises.csv\\\")\\n\",\n",
    "    \"    print(f\\\"Wger data loaded: {len(wger_df)} exercises\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Wger data not found. Run the fetch_data.py script first.\\\")\\n\",\n",
    "    \"    wger_df = None\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Explore ExerciseDB Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's explore the structure and content of the ExerciseDB data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"if exercisedb_df is not None:\\n\",\n",
    "    \"    # Display basic info\\n\",\n",
    "    \"    print(\\\"ExerciseDB DataFrame Info:\\\")\\n\",\n",
    "    \"    exercisedb_df.info()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"if exercisedb_df is not None:\\n\",\n",
    "    \"    # Display sample data\\n\",\n",
    "    \"    print(\\\"\\\\nSample ExerciseDB Data:\\\")\\n\",\n",
    "    \"    exercisedb_df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Distribution of Exercises by Body Part\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"if exercisedb_df is not None:\\n\",\n",
    "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"    bodypart_counts = exercisedb_df['bodyPart'].value_counts()\\n\",\n",
    "    \"    ax = sns.barplot(x=bodypart_counts.index, y=bodypart_counts.values)\\n\",\n",
    "    \"    plt.title('Number of Exercises by Body Part')\\n\",\n",
    "    \"    plt.xlabel('Body Part')\\n\",\n",
    "    \"    plt.ylabel('Count')\\n\",\n",
    "    \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add count labels on top of bars\\n\",\n",
    "    \"    for i, count in enumerate(bodypart_counts.values):\\n\",\n",
    "    \"        ax.text(i, count + 5, str(count), ha='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Distribution of Exercises by Target Muscle\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"if exercisedb_df is not None:\\n\",\n",
    "    \"    plt.figure(figsize=(14, 8))\\n\",\n",
    "    \"    target_counts = exercisedb_df['target'].value_counts().head(20)  # Top 20 for readability\\n\",\n",
    "    \"    ax = sns.barplot(x=target_counts.index, y=target_counts.values)\\n\",\n",
    "    \"    plt.title('Number of Exercises by Target Muscle (Top 20)')\\n\",\n",
    "    \"    plt.xlabel('Target Muscle')\\n\",\n",
    "    \"    plt.ylabel('Count')\\n\",\n",
    "    \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add count labels on top of bars\\n\",\n",
    "    \"    for i, count in enumerate(target_counts.values):\\n\",\n",
    "    \"        ax.text(i, count + 2, str(count), ha='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Distribution of Exercises by Equipment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"if exercisedb_df is not None:\\n\",\n",
    "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"    equipment_counts = exercisedb_df['equipment'].value_counts()\\n\",\n",
    "    \"    ax = sns.barplot(x=equipment_counts.index, y=equipment_counts.values)\\n\",\n",
    "    \"    plt.title('Number of Exercises by Equipment')\\n\",\n",
    "    \"    plt.xlabel('Equipment')\\n\",\n",
    "    \"    plt.ylabel('Count')\\n\",\n",
    "    \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add count labels on top of bars\\n\",\n",
    "    \"    for i, count in enumerate(equipment_counts.values):\\n\",\n",
    "    \"        ax.text(i, count + 5, str(count), ha='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Visualize Exercise GIFs\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's display some exercise GIFs to get a better understanding of the data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def display_exercise_gif(exercise_row):\\n\",\n",
    "    \"    \\\"\\\"\\\"Display exercise GIF and information\\\"\\\"\\\"\\n\",\n",
    "    \"    url = exercise_row['gifUrl']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        response = requests.get(url)\\n\",\n",
    "    \"        response.raise_for_status()\\n\",\n",
    "    \"        img = PILImage.open(io.BytesIO(response.content))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Display exercise info\\n\",\n",
    "    \"        print(f\\\"Name: {exercise_row['name']}\\\")\\n\",\n",
    "    \"        print(f\\\"Body Part: {exercise_row['bodyPart']}\\\")\\n\",\n",
    "    \"        print(f\\\"Target Muscle: {exercise_row['target']}\\\")\\n\",\n",
    "    \"        print(f\\\"Equipment: {exercise_row['equipment']}\\\")\\n\",\n",
    "    \"        print(\\\"\\\\nInstructions:\\\")\\n\",\n",
    "    \"        print(exercise_row['instructions'])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Display GIF\\n\",\n",
    "    \"        display(img)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error loading GIF: {e}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"if exercisedb_df is not None:\\n\",\n",
    "    \"    # Display a random sample of exercises\\n\",\n",
    "    \"    sample_exercises = exercisedb_df.sample(3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for _, exercise in sample_exercises.iterrows():\\n\",\n",
    "    \"        display_exercise_gif(exercise)\\n\",\n",
    "    \"        print(\\\"\\\\n\\\" + \\\"-\\\"*80 + \\\"\\\\n\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load Processed Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's load and examine the processed data after running the preprocessor.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load processed data\\n\",\n",
    "    \"processed_data_dir = \\\"data/processed\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check if processed data exists\\n\",\n",
    "    \"if os.path.exists(f\\\"{processed_data_dir}/exercisedb_processed.csv\\\"):\\n\",\n",
    "    \"    processed_df = pd.read_csv(f\\\"{processed_data_dir}/exercisedb_processed.csv\\\")\\n\",\n",
    "    \"    print(f\\\"Processed data loaded: {len(processed_df)} exercises\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Processed data not found. Run the preprocessor.py script first.\\\")\\n\",\n",
    "    \"    processed_df = None\\n\",\n",
    "    \"    \\n\",\n",
    "    \"if processed_df is not None:\\n\",\n",
    "    \"    # Display basic info\\n\",\n",
    "    \"    print(\\\"\\\\nProcessed DataFrame Info:\\\")\\n\",\n",
    "    \"    processed_df.info()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display sample data\\n\",\n",
    "    \"    print(\\\"\\\\nSample Processed Data:\\\")\\n\",\n",
    "    \"    display(processed_df.head())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Explore derived features\\n\",\n",
    "    \"    print(\\\"\\\\nExtracted Movement Patterns:\\\")\\n\",\n",
    "    \"    movement_pattern_counts = processed_df['movement_pattern'].value_counts()\\n\",\n",
    "    \"    display(movement_pattern_counts)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nExtracted Joints Used:\\\")\\n\",\n",
    "    \"    # Since joints_used is a list stored as string, we need to process it\\n\",\n",
    "    \"    all_joints = []\\n\",\n",
    "    \"    for joints_str in processed_df['joints_used']:\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            joints = eval(joints_str) if isinstance(joints_str, str) else []\\n\",\n",
    "    \"            all_joints.extend(joints)\\n\",\n",
    "    \"        except:\\n\",\n",
    "    \"            pass\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    joints_counts = pd.Series(all_joints).value_counts()\\n\",\n",
    "    \"    display(joints_counts)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nCompound vs Isolation Exercises:\\\")\\n\",\n",
    "    \"    compound_counts = processed_df['is_compound'].value_counts()\\n\",\n",
    "    \"    display(compound_counts)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Visualize movement patterns\\n\",\n",
    "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"    ax = sns.barplot(x=movement_pattern_counts.index, y=movement_pattern_counts.values)\\n\",\n",
    "    \"    plt.title('Distribution of Exercise Movement Patterns')\\n\",\n",
    "    \"    plt.xlabel('Movement Pattern')\\n\",\n",
    "    \"    plt.ylabel('Count')\\n\",\n",
    "    \"    plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add count labels on top of bars\\n\",\n",
    "    \"    for i, count in enumerate(movement_pattern_counts.values):\\n\",\n",
    "    \"        ax.text(i, count + 2, str(count), ha='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Check for text features (TF-IDF)\\n\",\n",
    "    \"    tfidf_cols = [col for col in processed_df.columns if col.startswith('tfidf_')]\\n\",\n",
    "    \"    if tfidf_cols:\\n\",\n",
    "    \"        print(f\\\"\\\\nNumber of TF-IDF features: {len(tfidf_cols)}\\\")\\n\",\n",
    "    \"        print(\\\"Sample TF-IDF features:\\\")\\n\",\n",
    "    \"        display(processed_df[tfidf_cols[:5]].head())\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Visualize the most common terms\\n\",\n",
    "    \"        feature_means = processed_df[tfidf_cols].mean().sort_values(ascending=False)\\n\",\n",
    "    \"        top_features = feature_means.head(15)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"        ax = sns.barplot(x=top_features.index, y=top_features.values)\\n\",\n",
    "    \"        plt.title('Most Common TF-IDF Features Across Exercises')\\n\",\n",
    "    \"        plt.xlabel('Feature')\\n\",\n",
    "    \"        plt.ylabel('Mean TF-IDF Value')\\n\",\n",
    "    \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# If predictions are available, let's analyze them\\n\",\n",
    "    \"if os.path.exists(\\\"data/predictions.csv\\\"):\\n\",\n",
    "    \"    predictions_df = pd.read_csv(\\\"data/predictions.csv\\\")\\n\",\n",
    "    \"    print(f\\\"\\\\nPredictions loaded: {len(predictions_df)} exercises\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Compare predictions with true values\\n\",\n",
    "    \"    for col in ['movement_pattern', 'is_compound', 'risk_assessment']:\\n\",\n",
    "    \"        pred_col = f\\\"{col}_pred\\\"\\n\",\n",
    "    \"        if pred_col in predictions_df.columns and col in predictions_df.columns:\\n\",\n",
    "    \"            print(f\\\"\\\\nConfusion Matrix for {col}:\\\")\\n\",\n",
    "    \"            conf_matrix = pd.crosstab(predictions_df[col], predictions_df[pred_col], \\n\",\n",
    "    \"                                      rownames=['Actual'], colnames=['Predicted'])\\n\",\n",
    "    \"            display(conf_matrix)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Calculate accuracy\\n\",\n",
    "    \"            accuracy = (predictions_df[col] == predictions_df[pred_col]).mean() * 100\\n\",\n",
    "    \"            print(f\\\"Accuracy: {accuracy:.2f}%\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Visualize confusion matrix\\n\",\n",
    "    \"            plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"            sns.heatmap(conf_matrix, annot=True, fmt=\\\"d\\\", cmap=\\\"Blues\\\")\\n\",\n",
    "    \"            plt.title(f'Confusion Matrix for {col}')\\n\",\n",
    "    \"            plt.tight_layout()\\n\",\n",
    "    \"            plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\nNo predictions found. Run the prediction script first.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Conclusion\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"CONCLUSION\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"This notebook has helped us explore the exercise data and understand its structure.\\\")\\n\",\n",
    "    \"print(\\\"We've seen the distribution of exercises by body part, target muscle, and equipment.\\\")\\n\",\n",
    "    \"print(\\\"We've also analyzed the derived features such as movement patterns and compound vs isolation exercises.\\\")\\n\",\n",
    "    \"print(\\\"\\\\nNext steps:\\\")\\n\",\n",
    "    \"print(\\\"1. Run the preprocessing script to extract features from the raw data\\\")\\n\",\n",
    "    \"print(\\\"2. Train the classification models to predict exercise attributes\\\")\\n\",\n",
    "    \"print(\\\"3. Evaluate model performance and refine the models\\\")\\n\",\n",
    "    \"print(\\\"4. Integrate the models into a full exercise classification system\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Check for pose features (landmarks)\\n\",\n",
    "    \"if processed_df is not None:\\n\",\n",
    "    \"    landmark_cols = [col for col in processed_df.columns if col.startswith('landmark_')]\\n\",\n",
    "    \"    if landmark_cols:\\n\",\n",
    "    \"        print(f\\\"\\\\nNumber of landmark features: {len(landmark_cols)}\\\")\\n\",\n",
    "    \"        print(\\\"Sample landmark features:\\\")\\n\",\n",
    "    \"        display(processed_df[landmark_cols[:5]].head())\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # PCA visualization of landmarks\\n\",\n",
    "    \"        from sklearn.decomposition import PCA\\n\",\n",
    "    \"        from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Scale the landmark data\\n\",\n",
    "    \"        landmark_data = processed_df[landmark_cols].fillna(0)\\n\",\n",
    "    \"        scaler = StandardScaler()\\n\",\n",
    "    \"        scaled_data = scaler.fit_transform(landmark_data)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Apply PCA\\n\",\n",
    "    \"        pca = PCA(n_components=2)\\n\",\n",
    "    \"        pca_result = pca.fit_transform(scaled_data)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create DataFrame for plotting\\n\",\n",
    "    \"        pca_df = pd.DataFrame({\\n\",\n",
    "    \"            'PCA1': pca_result[:, 0],\\n\",\n",
    "    \"            'PCA2': pca_result[:, 1],\\n\",\n",
    "    \"            'movement_pattern': processed_df['movement_pattern'].values,\\n\",\n",
    "    \"            'bodypart': processed_df['bodypart'].values\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot by movement pattern\\n\",\n",
    "    \"        plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"        sns.scatterplot(x='PCA1', y='PCA2', hue='movement_pattern', data=pca_df, palette='viridis')\\n\",\n",
    "    \"        plt.title('PCA of Exercise Pose Landmarks (colored by Movement Pattern)')\\n\",\n",
    "    \"        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot by bodypart\\n\",\n",
    "    \"        plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"        sns.scatterplot(x='PCA1', y='PCA2', hue='bodypart', data=pca_df, palette='tab10')\\n\",\n",
    "    \"        plt.title('PCA of Exercise Pose Landmarks (colored by Body Part)')\\n\",\n",
    "    \"        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Relationship between bodypart and movement pattern\\n\",\n",
    "    \"    plt.figure(figsize=(16, 10))\\n\",\n",
    "    \"    body_movement = pd.crosstab(processed_df['bodypart'], processed_df['movement_pattern'])\\n\",\n",
    "    \"    sns.heatmap(body_movement, annot=True, cmap=\\\"YlGnBu\\\", fmt=\\\"d\\\", linewidths=.5)\\n\",\n",
    "    \"    plt.title('Relationship Between Body Part and Movement Pattern')\\n\",\n",
    "    \"    plt.ylabel('Body Part')\\n\",\n",
    "    \"    plt.xlabel('Movement Pattern')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Relationship between equipment and movement pattern\\n\",\n",
    "    \"    plt.figure(figsize=(16, 10))\\n\",\n",
    "    \"    equip_movement = pd.crosstab(processed_df['equipment'], processed_df['movement_pattern'])\\n\",\n",
    "    \"    sns.heatmap(equip_movement, annot=True, cmap=\\\"YlGnBu\\\", fmt=\\\"d\\\", linewidths=.5)\\n\",\n",
    "    \"    plt.title('Relationship Between Equipment and Movement Pattern')\\n\",\n",
    "    \"    plt.ylabel('Equipment')\\n\",\n",
    "    \"    \",\n",
    "    \"    plt.xlabel('Movement Pattern')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Visualize compound vs isolation\\n\",\n",
    "    \"    plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"    compound_df = pd.DataFrame({'Exercise Type': ['Compound', 'Isolation'], \\n\",\n",
    "    \"                               'Count': [compound_counts.get(True, 0), compound_counts.get(False, 0)]})\\n\",\n",
    "    \"    ax = sns.barplot(x='Exercise Type', y='Count', data=compound_df)\\n\",\n",
    "    \"    plt.title('Compound vs Isolation Exercises')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add count labels on top of bars\\n\",\n",
    "    \"    for i, count in enumerate(compound_df['Count']):\\n\",\n",
    "    \"        ax.text(i, count + 5, str(count), ha='center')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
