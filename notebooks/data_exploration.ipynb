{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Data Exploration\n",
    "\n",
    "This notebook is for exploring and visualizing the exercise data fetched from the APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "import requests\n",
    "from PIL import Image as PILImage\n",
    "import io\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Let's load and examine the fetched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExerciseDB data not found. Run the fetch_data.py script first.\n",
      "Wger data not found. Run the fetch_data.py script first.\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "raw_data_dir = \"data/raw\"\n",
    "exercisedb_dir = f\"{raw_data_dir}/exercisedb\"\n",
    "wger_dir = f\"{raw_data_dir}/wger\"\n",
    "\n",
    "# Check if data exists\n",
    "if os.path.exists(f\"{exercisedb_dir}/all_exercises.csv\"):\n",
    "    exercisedb_df = pd.read_csv(f\"{exercisedb_dir}/all_exercises.csv\")\n",
    "    print(f\"ExerciseDB data loaded: {len(exercisedb_df)} exercises\")\n",
    "else:\n",
    "    print(\"ExerciseDB data not found. Run the fetch_data.py script first.\")\n",
    "    exercisedb_df = None\n",
    "\n",
    "if os.path.exists(f\"{wger_dir}/all_exercises.csv\"):\n",
    "    wger_df = pd.read_csv(f\"{wger_dir}/all_exercises.csv\")\n",
    "    print(f\"Wger data loaded: {len(wger_df)} exercises\")\n",
    "else:\n",
    "    print(\"Wger data not found. Run the fetch_data.py script first.\")\n",
    "    wger_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ExerciseDB Data\n",
    "\n",
    "Let's explore the structure and content of the ExerciseDB data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercisedb_df is not None:\n",
    "    # Display basic info\n",
    "    print(\"ExerciseDB DataFrame Info:\")\n",
    "    exercisedb_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercisedb_df is not None:\n",
    "    # Display sample data\n",
    "    print(\"\\nSample ExerciseDB Data:\")\n",
    "    exercisedb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Exercises by Body Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercisedb_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bodypart_counts = exercisedb_df['bodyPart'].value_counts()\n",
    "    ax = sns.barplot(x=bodypart_counts.index, y=bodypart_counts.values)\n",
    "    plt.title('Number of Exercises by Body Part')\n",
    "    plt.xlabel('Body Part')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for i, count in enumerate(bodypart_counts.values):\n",
    "        ax.text(i, count + 5, str(count), ha='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Exercises by Target Muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercisedb_df is not None:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    target_counts = exercisedb_df['target'].value_counts().head(20)  # Top 20 for readability\n",
    "    ax = sns.barplot(x=target_counts.index, y=target_counts.values)\n",
    "    plt.title('Number of Exercises by Target Muscle (Top 20)')\n",
    "    plt.xlabel('Target Muscle')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for i, count in enumerate(target_counts.values):\n",
    "        ax.text(i, count + 2, str(count), ha='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Exercises by Equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercisedb_df is not None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    equipment_counts = exercisedb_df['equipment'].value_counts()\n",
    "    ax = sns.barplot(x=equipment_counts.index, y=equipment_counts.values)\n",
    "    plt.title('Number of Exercises by Equipment')\n",
    "    plt.xlabel('Equipment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for i, count in enumerate(equipment_counts.values):\n",
    "        ax.text(i, count + 5, str(count), ha='center')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Exercise GIFs\n",
    "\n",
    "Let's display some exercise GIFs to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_exercise_gif(exercise_row):\n",
    "    \"\"\"Display exercise GIF and information\"\"\"\n",
    "    url = exercise_row['gifUrl']\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        img = PILImage.open(io.BytesIO(response.content))\n",
    "        \n",
    "        # Display exercise info\n",
    "        print(f\"Name: {exercise_row['name']}\")\n",
    "        print(f\"Body Part: {exercise_row['bodyPart']}\")\n",
    "        print(f\"Target Muscle: {exercise_row['target']}\")\n",
    "        print(f\"Equipment: {exercise_row['equipment']}\")\n",
    "        print(\"\\nInstructions:\")\n",
    "        print(exercise_row['instructions'])\n",
    "        \n",
    "        # Display GIF\n",
    "        display(img)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading GIF: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exercisedb_df is not None:\n",
    "    # Display a random sample of exercises\n",
    "    sample_exercises = exercisedb_df.sample(3)\n",
    "    \n",
    "    for _, exercise in sample_exercises.iterrows():\n",
    "        display_exercise_gif(exercise)\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data\n",
    "\n",
    "Let's load and examine the processed data after running the preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data not found. Run the preprocessor.py script first.\n",
      "\n",
      "No predictions found. Run the prediction script first.\n",
      "\n",
      "================================================================================\n",
      "CONCLUSION\n",
      "================================================================================\n",
      "This notebook has helped us explore the exercise data and understand its structure.\n",
      "We've seen the distribution of exercises by body part, target muscle, and equipment.\n",
      "We've also analyzed the derived features such as movement patterns and compound vs isolation exercises.\n",
      "\n",
      "Next steps:\n",
      "1. Run the preprocessing script to extract features from the raw data\n",
      "2. Train the classification models to predict exercise attributes\n",
      "3. Evaluate model performance and refine the models\n",
      "4. Integrate the models into a full exercise classification system\n"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "processed_data_dir = \"data/processed\"\n",
    "\n",
    "# Check if processed data exists\n",
    "if os.path.exists(f\"{processed_data_dir}/exercisedb_processed.csv\"):\n",
    "    processed_df = pd.read_csv(f\"{processed_data_dir}/exercisedb_processed.csv\")\n",
    "    print(f\"Processed data loaded: {len(processed_df)} exercises\")\n",
    "else:\n",
    "    print(\"Processed data not found. Run the preprocessor.py script first.\")\n",
    "    processed_df = None\n",
    "    \n",
    "if processed_df is not None:\n",
    "    # Display basic info\n",
    "    print(\"\\nProcessed DataFrame Info:\")\n",
    "    processed_df.info()\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nSample Processed Data:\")\n",
    "    display(processed_df.head())\n",
    "    \n",
    "    # Explore derived features\n",
    "    print(\"\\nExtracted Movement Patterns:\")\n",
    "    movement_pattern_counts = processed_df['movement_pattern'].value_counts()\n",
    "    display(movement_pattern_counts)\n",
    "    \n",
    "    print(\"\\nExtracted Joints Used:\")\n",
    "    # Since joints_used is a list stored as string, we need to process it\n",
    "    all_joints = []\n",
    "    for joints_str in processed_df['joints_used']:\n",
    "        try:\n",
    "            joints = eval(joints_str) if isinstance(joints_str, str) else []\n",
    "            all_joints.extend(joints)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    joints_counts = pd.Series(all_joints).value_counts()\n",
    "    display(joints_counts)\n",
    "    \n",
    "    print(\"\\nCompound vs Isolation Exercises:\")\n",
    "    compound_counts = processed_df['is_compound'].value_counts()\n",
    "    display(compound_counts)\n",
    "    \n",
    "    # Visualize movement patterns\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=movement_pattern_counts.index, y=movement_pattern_counts.values)\n",
    "    plt.title('Distribution of Exercise Movement Patterns')\n",
    "    plt.xlabel('Movement Pattern')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for i, count in enumerate(movement_pattern_counts.values):\n",
    "        ax.text(i, count + 2, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for text features (TF-IDF)\n",
    "    tfidf_cols = [col for col in processed_df.columns if col.startswith('tfidf_')]\n",
    "    if tfidf_cols:\n",
    "        print(f\"\\nNumber of TF-IDF features: {len(tfidf_cols)}\")\n",
    "        print(\"Sample TF-IDF features:\")\n",
    "        display(processed_df[tfidf_cols[:5]].head())\n",
    "        \n",
    "        # Visualize the most common terms\n",
    "        feature_means = processed_df[tfidf_cols].mean().sort_values(ascending=False)\n",
    "        top_features = feature_means.head(15)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.barplot(x=top_features.index, y=top_features.values)\n",
    "        plt.title('Most Common TF-IDF Features Across Exercises')\n",
    "        plt.xlabel('Feature')\n",
    "        plt.ylabel('Mean TF-IDF Value')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# If predictions are available, let's analyze them\n",
    "if os.path.exists(\"data/predictions.csv\"):\n",
    "    predictions_df = pd.read_csv(\"data/predictions.csv\")\n",
    "    print(f\"\\nPredictions loaded: {len(predictions_df)} exercises\")\n",
    "    \n",
    "    # Compare predictions with true values\n",
    "    for col in ['movement_pattern', 'is_compound', 'risk_assessment']:\n",
    "        pred_col = f\"{col}_pred\"\n",
    "        if pred_col in predictions_df.columns and col in predictions_df.columns:\n",
    "            print(f\"\\nConfusion Matrix for {col}:\")\n",
    "            conf_matrix = pd.crosstab(predictions_df[col], predictions_df[pred_col], \n",
    "                                      rownames=['Actual'], colnames=['Predicted'])\n",
    "            display(conf_matrix)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (predictions_df[col] == predictions_df[pred_col]).mean() * 100\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "            # Visualize confusion matrix\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.title(f'Confusion Matrix for {col}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"\\nNo predictions found. Run the prediction script first.\")\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*80)\n",
    "print(\"This notebook has helped us explore the exercise data and understand its structure.\")\n",
    "print(\"We've seen the distribution of exercises by body part, target muscle, and equipment.\")\n",
    "print(\"We've also analyzed the derived features such as movement patterns and compound vs isolation exercises.\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run the preprocessing script to extract features from the raw data\")\n",
    "print(\"2. Train the classification models to predict exercise attributes\")\n",
    "print(\"3. Evaluate model performance and refine the models\")\n",
    "print(\"4. Integrate the models into a full exercise classification system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for pose features (landmarks)\n",
    "if processed_df is not None:\n",
    "    landmark_cols = [col for col in processed_df.columns if col.startswith('landmark_')]\n",
    "    if landmark_cols:\n",
    "        print(f\"\\nNumber of landmark features: {len(landmark_cols)}\")\n",
    "        print(\"Sample landmark features:\")\n",
    "        display(processed_df[landmark_cols[:5]].head())\n",
    "        \n",
    "        # PCA visualization of landmarks\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        # Scale the landmark data\n",
    "        landmark_data = processed_df[landmark_cols].fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(landmark_data)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        pca_df = pd.DataFrame({\n",
    "            'PCA1': pca_result[:, 0],\n",
    "            'PCA2': pca_result[:, 1],\n",
    "            'movement_pattern': processed_df['movement_pattern'].values,\n",
    "            'bodypart': processed_df['bodypart'].values\n",
    "        })\n",
    "        \n",
    "        # Plot by movement pattern\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.scatterplot(x='PCA1', y='PCA2', hue='movement_pattern', data=pca_df, palette='viridis')\n",
    "        plt.title('PCA of Exercise Pose Landmarks (colored by Movement Pattern)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot by bodypart\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.scatterplot(x='PCA1', y='PCA2', hue='bodypart', data=pca_df, palette='tab10')\n",
    "        plt.title('PCA of Exercise Pose Landmarks (colored by Body Part)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Relationship between bodypart and movement pattern\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    body_movement = pd.crosstab(processed_df['bodypart'], processed_df['movement_pattern'])\n",
    "    sns.heatmap(body_movement, annot=True, cmap=\"YlGnBu\", fmt=\"d\", linewidths=.5)\n",
    "    plt.title('Relationship Between Body Part and Movement Pattern')\n",
    "    plt.ylabel('Body Part')\n",
    "    plt.xlabel('Movement Pattern')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Relationship between equipment and movement pattern\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    equip_movement = pd.crosstab(processed_df['equipment'], processed_df['movement_pattern'])\n",
    "    sns.heatmap(equip_movement, annot=True, cmap=\"YlGnBu\", fmt=\"d\", linewidths=.5)\n",
    "    plt.title('Relationship Between Equipment and Movement Pattern')\n",
    "    plt.ylabel('Equipment')\n",
    "    \n",
    "    plt.xlabel('Movement Pattern')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize compound vs isolation\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    compound_df = pd.DataFrame({'Exercise Type': ['Compound', 'Isolation'], \n",
    "                               'Count': [compound_counts.get(True, 0), compound_counts.get(False, 0)]})\n",
    "    ax = sns.barplot(x='Exercise Type', y='Count', data=compound_df)\n",
    "    plt.title('Compound vs Isolation Exercises')\n",
    "    \n",
    "    # Add count labels on top of bars\n",
    "    for i, count in enumerate(compound_df['Count']):\n",
    "        ax.text(i, count + 5, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
