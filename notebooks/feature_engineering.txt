    # Save intermediate result\n",
    "    pose_features_df.to_csv(f\"{PROCESSED_DATA_DIR}/pose_features.csv\", index=False)\n",
    "    print(f\"Pose features saved to {PROCESSED_DATA_DIR}/pose_features.csv\")\n",
    "\n",
    "# Analyze pose features\n",
    "if 'pose_features_df' in locals():\n",
    "    # Analyze pose positions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    position_counts = pose_features_df['pose_position'].value_counts()\n",
    "    ax = sns.barplot(x=position_counts.index, y=position_counts.values)\n",
    "    plt.title('Distribution of Exercise Positions')\n",
    "    plt.xlabel('Position')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, count in enumerate(position_counts.values):\n",
    "        ax.text(i, count + 0.1, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze movement planes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plane_counts = pose_features_df['pose_movement_plane'].value_counts()\n",
    "    ax = sns.barplot(x=plane_counts.index, y=plane_counts.values)\n",
    "    plt.title('Distribution of Movement Planes')\n",
    "    plt.xlabel('Movement Plane')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, count in enumerate(plane_counts.values):\n",
    "        ax.text(i, count + 0.1, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Histogram of symmetry scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(pose_features_df['pose_symmetry'], bins=20, alpha=0.7)\n",
    "    plt.axvline(pose_features_df['pose_symmetry'].mean(), color='red', linestyle='dashed', linewidth=2)\n",
    "    plt.title('Distribution of Pose Symmetry Scores')\n",
    "    plt.xlabel('Symmetry Score (higher is more symmetric)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show(){
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Classification Feature Engineering\n",
    "\n",
    "This notebook demonstrates the feature engineering process for the exercise classification project. We'll extract features from exercise data to classify exercises based on various attributes including:\n",
    "\n",
    "- Target muscle groups\n",
    "- Required equipment\n",
    "- Movement patterns\n",
    "- Intensity/experience levels\n",
    "- Exercise types\n",
    "- Quality of movement\n",
    "- Risk assessment\n",
    "\n",
    "We'll use both text-based features from exercise descriptions and pose-based features from exercise images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set Matplotlib and Seaborn styles\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# For displaying images in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Exercise Data\n",
    "\n",
    "First, let's load the raw exercise data that we fetched from the APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set data paths\n",
    "RAW_DATA_DIR = \"data/raw\"\n",
    "PROCESSED_DATA_DIR = \"data/processed\"\n",
    "EXERCISEDB_DIR = f\"{RAW_DATA_DIR}/exercisedb\"\n",
    "MODEL_DIR = \"models\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load ExerciseDB data\n",
    "exercisedb_path = f\"{EXERCISEDB_DIR}/all_exercises.csv\"\n",
    "\n",
    "if os.path.exists(exercisedb_path):\n",
    "    df = pd.read_csv(exercisedb_path)\n",
    "    print(f\"Loaded {len(df)} exercises from ExerciseDB\")\n",
    "else:\n",
    "    print(\"ExerciseDB data not found. Please run the data fetcher first.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display basic info and sample data\n",
    "if df is not None:\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df.info()\n",
    "    \n",
    "    print(\"\\nSample Data:\")\n",
    "    display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Preprocessing\n",
    "\n",
    "Let's clean and prepare the data for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def clean_dataset(df):\n",
    "    \"\"\"Clean and preprocess the raw dataset\"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # Make column names lowercase and replace spaces with underscores\n",
    "    cleaned_df.columns = [col.lower().replace(' ', '_') for col in cleaned_df.columns]\n",
    "    \n",
    "    # Convert all string columns to lowercase\n",
    "    for col in cleaned_df.select_dtypes(include=['object']).columns:\n",
    "        if col in ['instructions', 'name', 'bodypart', 'target', 'equipment']:\n",
    "            cleaned_df[col] = cleaned_df[col].str.lower()\n",
    "    \n",
    "    # Fill missing values\n",
    "    if 'instructions' in cleaned_df.columns:\n",
    "        cleaned_df['instructions'].fillna('', inplace=True)\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# Clean the dataset\n",
    "if df is not None:\n",
    "    cleaned_df = clean_dataset(df)\n",
    "    print(f\"Cleaned dataset with {len(cleaned_df)} rows and {len(cleaned_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check the unique values in key categorical columns\n",
    "if 'cleaned_df' in locals():\n",
    "    categorical_cols = ['bodypart', 'target', 'equipment']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in cleaned_df.columns:\n",
    "            unique_vals = cleaned_df[col].unique()\n",
    "            print(f\"\\n{col.capitalize()} unique values ({len(unique_vals)}):\")\n",
    "            print(sorted(unique_vals)[:10], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Feature Extraction\n",
    "\n",
    "Now, let's extract features from the text data (exercise names and instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class TextFeatureExtractor:\n",
    "    \"\"\"Extract features from exercise text data\"\"\"\n",
    "    def __init__(self, max_features=100):\n",
    "        self.max_features = max_features\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=max_features,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2\n",
    "        )\n",
    "    \n",
    "    def extract_features(self, df):\n",
    "        \"\"\"Extract text features from a DataFrame\"\"\"\n",
    "        # Combine name and instructions for TF-IDF\n",
    "        if 'instructions' in df.columns and 'name' in df.columns:\n",
    "            df['text_combined'] = df['name'] + ' ' + df['instructions'].fillna('')\n",
    "        elif 'name' in df.columns:\n",
    "            df['text_combined'] = df['name']\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must contain 'name' column\")\n",
    "        \n",
    "        # Extract TF-IDF features\n",
    "        print(\"Extracting TF-IDF features...\")\n",
    "        tfidf_matrix = self.tfidf_vectorizer.fit_transform(df['text_combined'])\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        feature_names = self.tfidf_vectorizer.get_feature_names_out()\n",
    "        tfidf_df = pd.DataFrame(\n",
    "            tfidf_matrix.toarray(), \n",
    "            columns=[f\"tfidf_{f}\" for f in feature_names]\n",
    "        )\n",
    "        \n",
    "        # Add to original DataFrame\n",
    "        result_df = pd.concat([df, tfidf_df], axis=1)\n",
    "        \n",
    "        print(f\"Extracted {len(feature_names)} TF-IDF features\")\n",
    "        return result_df\n",
    "\n",
    "    def display_exercise_with_landmarks(self, exercise_id, image_dir=None):\n",
    "        \"\"\"Display an exercise image with landmark annotations\"\"\"\n",
    "        img_dir = image_dir or self.image_dir\n",
    "        annotated_path = f\"{img_dir}/{exercise_id}_annotated.jpg\"\n",
    "        original_path = f\"{img_dir}/{exercise_id}.jpg\"\n",
    "        \n",
    "        # Check if annotated image exists\n",
    "        if os.path.exists(annotated_path):\n",
    "            img = cv2.imread(annotated_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        elif os.path.exists(original_path):\n",
    "            img = cv2.imread(original_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            print(f\"No image found for exercise {exercise_id}\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Exercise {exercise_id} with Pose Landmarks\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Create a function to display sample images with landmarks\n",
    "def show_sample_poses(df, pose_extractor, n=3):\n",
    "    \"\"\"Display sample exercise images with landmarks\"\"\"\n",
    "    # Select n random samples with valid images\n",
    "    if 'id' in df.columns:\n",
    "        samples = df.sample(min(n, len(df)))\n",
    "        for _, row in samples.iterrows():\n",
    "            exercise_id = row['id']\n",
    "            print(f\"\\nExercise: {row.get('name', 'Unknown')}\")\n",
    "            print(f\"Body Part: {row.get('bodypart', 'Unknown')}\")\n",
    "            print(f\"Movement Pattern: {row.get('movement_pattern', 'Unknown')}\")\n",
    "            print(f\"Pose Position: {row.get('pose_position', 'Unknown')}\")\n",
    "            pose_extractor.display_exercise_with_landmarks(exercise_id)\n",
    "\n",
    "# Initialize pose feature extractor and process a sample of images\n",
    "if 'text_attr_df' in locals():\n",
    "    pose_extractor = PoseFeatureExtractor()\n",
    "    \n",
    "    # Process a limited number of images for demonstration\n",
    "    limit = 5  # Set this to a reasonable number based on your computational resources\n",
    "    pose_df = pose_extractor.download_and_process_images(text_attr_df, limit=limit)\n",
    "    \n",
    "    # Extract derived pose features\n",
    "    pose_features_df = pose_extractor.extract_pose_features(pose_df)\n",
    "    \n",
    "    # Display sample poses\n",
    "    show_sample_poses(pose_features_df, pose_extractor)\n",
    "    \n",
    "    # Save intermediate result\n",
    "    pose_features_df.to_csv(f\"{PROCESSED_DATA_DIR}/pose_features.csv\", index=False)\n",
    "    print(f\"Pose features saved to {PROCESSED_DATA_DIR}/pose_features.csv\")\n",
    "    \n",
    "    def extract_keyword_features(self, df):\n",
    "        \"\"\"Extract keyword-based features from text\"\"\"\n",
    "        result_df = df.copy()\n",
    "        \n",
    "        print(\"Extracting keyword features...\")\n",
    "        \n",
    "        # Define keyword dictionaries for various categories\n",
    "        keywords = {\n",
    "            'compound_keywords': ['compound', 'multi-joint', 'full body', 'complex'],\n",
    "            'isolation_keywords': ['isolation', 'single-joint', 'isolate', 'focus'],\n",
    "            'beginner_keywords': ['beginner', 'basic', 'simple', 'easy', 'starter'],\n",
    "            'advanced_keywords': ['advanced', 'difficult', 'challenging', 'expert'],\n",
    "            'high_intensity_keywords': ['high intensity', 'explosive', 'power', 'maximum'],\n",
    "            'low_intensity_keywords': ['low intensity', 'gentle', 'moderate', 'light'],\n",
    "            'strength_keywords': ['strength', 'power', 'force', 'heavy'],\n",
    "            'hypertrophy_keywords': ['hypertrophy', 'muscle growth', 'build muscle', 'volume'],\n",
    "            'cardio_keywords': ['cardio', 'cardiovascular', 'aerobic', 'heart rate'],\n",
    "            'flexibility_keywords': ['flexibility', 'stretch', 'mobility', 'range of motion'],\n",
    "            'risky_keywords': ['caution', 'careful', 'risk', 'injury', 'dangerous'],\n",
    "            'safe_keywords': ['safe', 'beginner-friendly', 'low-impact']\n",
    "        }\n",
    "        \n",
    "        # Create keyword feature columns\n",
    "        for category, words in keywords.items():\n",
    "            result_df[f'kw_{category}'] = result_df['text_combined'].apply(\n",
    "                lambda x: sum(1 for word in words if word in str(x).lower())\n",
    "            )\n",
    "        \n",
    "        print(f\"Extracted {len(keywords)} keyword feature categories\")\n",
    "        return result_df\n",
    "    \n",
    "    def extract_movement_pattern(self, name, instructions):\n",
    "        \"\"\"Extract movement pattern from exercise name and instructions\"\"\"\n",
    "        name = name.lower() if isinstance(name, str) else \"\"\n",
    "        instructions = instructions.lower() if isinstance(instructions, str) else \"\"\n",
    "        text = name + \" \" + instructions\n",
    "        \n",
    "        # Basic pattern matching\n",
    "        if any(word in text for word in ['squat', 'lunge', 'step', 'leg press']):\n",
    "            return 'squat'\n",
    "        elif any(word in text for word in ['hinge', 'deadlift', 'hip thrust', 'good morning', 'swing']):\n",
    "            return 'hinge'\n",
    "        elif any(word in text for word in ['push', 'press', 'bench', 'chest', 'shoulder press', 'overhead']):\n",
    "            return 'push'\n",
    "        elif any(word in text for word in ['pull', 'row', 'chin', 'pull-up', 'pullup', 'pulldown', 'lat']):\n",
    "            return 'pull'\n",
    "        elif any(word in text for word in ['rotation', 'twist', 'turn', 'russian twist', 'woodchop']):\n",
    "            return 'rotation'\n",
    "        elif any(word in text for word in ['carry', 'walk', 'farmer', 'suitcase', 'turkish']):\n",
    "            return 'carry'\n",
    "        elif any(word in text for word in ['plank', 'bridge', 'hold', 'isometric', 'hollow']):\n",
    "            return 'isometric'\n",
    "        elif any(word in text for word in ['jump', 'hop', 'bound', 'plyometric', 'explosive']):\n",
    "            return 'plyometric'\n",
    "        elif any(word in text for word in ['curl', 'extension', 'raise', 'isolation']):\n",
    "            return 'isolation'\n",
    "        else:\n",
    "            return 'other'\n",
    "    \n",
    "    def extract_joints_used(self, instructions):\n",
    "        \"\"\"Extract joints used from instructions\"\"\"\n",
    "        if not isinstance(instructions, str):\n",
    "            return []\n",
    "            \n",
    "        instructions = instructions.lower()\n",
    "        \n",
    "        joints = []\n",
    "        joint_keywords = {\n",
    "            'shoulder': ['shoulder', 'deltoid', 'rotator cuff'],\n",
    "            'elbow': ['elbow', 'bicep', 'tricep'],\n",
    "            'wrist': ['wrist', 'forearm'],\n",
    "            'hip': ['hip', 'glute', 'buttock', 'gluteal'],\n",
    "            'knee': ['knee', 'quad', 'hamstring'],\n",
    "            'ankle': ['ankle', 'calf', 'shin'],\n",
    "            'spine': ['spine', 'back', 'lumbar', 'thoracic', 'cervical', 'neck', 'core', 'abdominal']\n",
    "        }\n",
    "        \n",
    "        for joint, keywords in joint_keywords.items():\n",
    "            if any(keyword in instructions for keyword in keywords):\n",
    "                joints.append(joint)\n",
    "                \n",
    "        return joints\n",
    "    \n",
    "    def extract_exercise_attributes(self, df):\n",
    "        \"\"\"Extract exercise attributes based on text analysis\"\"\"\n",
    "        result_df = df.copy()\n",
    "        \n",
    "        print(\"Extracting exercise attributes from text...\")\n",
    "        \n",
    "        # Extract movement patterns\n",
    "        result_df['movement_pattern'] = result_df.apply(\n",
    "            lambda row: self.extract_movement_pattern(\n",
    "                row['name'] if 'name' in row else \"\", \n",
    "                row['instructions'] if 'instructions' in row else \"\"\n",
    "            ), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Extract joints used\n",
    "        result_df['joints_used'] = result_df.apply(\n",
    "            lambda row: str(self.extract_joints_used(\n",
    "                row['instructions'] if 'instructions' in row else \"\"\n",
    "            )), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Determine if compound exercise\n",
    "        result_df['is_compound'] = result_df.apply(\n",
    "            lambda row: len(eval(row['joints_used'])) > 1 if row['joints_used'] != '[]' else False, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Determine exercise type\n",
    "        # Prioritize: strength, hypertrophy, cardio, flexibility\n",
    "        def determine_exercise_type(row):\n",
    "            text = row['text_combined'].lower() if 'text_combined' in row else \"\"\n",
    "            \n",
    "            # Check keyword scores\n",
    "            strength_score = row.get('kw_strength_keywords', 0)\n",
    "            hypertrophy_score = row.get('kw_hypertrophy_keywords', 0)\n",
    "            cardio_score = row.get('kw_cardio_keywords', 0)\n",
    "            flexibility_score = row.get('kw_flexibility_keywords', 0)\n",
    "            \n",
    "            # Determine based on highest score\n",
    "            scores = {\n",
    "                'strength': strength_score,\n",
    "                'hypertrophy': hypertrophy_score,\n",
    "                'cardio': cardio_score,\n",
    "                'flexibility': flexibility_score\n",
    "            }\n",
    "            \n",
    "            max_type = max(scores, key=scores.get)\n",
    "            max_score = scores[max_type]\n",
    "            \n",
    "            if max_score > 0:\n",
    "                return max_type\n",
    "            else:\n",
    "                # Default based on bodypart and equipment\n",
    "                bodypart = row.get('bodypart', '').lower()\n",
    "                equipment = row.get('equipment', '').lower()\n",
    "                \n",
    "                if equipment in ['barbell', 'dumbbell', 'kettlebell']:\n",
    "                    return 'strength'\n",
    "                elif 'cardio' in bodypart or equipment in ['body weight', 'rope']:\n",
    "                    return 'cardio'\n",
    "                else:\n",
    "                    return 'hypertrophy'  # Default for most exercises\n",
    "        \n",
    "        result_df['exercise_type'] = result_df.apply(determine_exercise_type, axis=1)\n",
    "        \n",
    "        # Determine intensity level\n",
    "        def determine_intensity(row):\n",
    "            beginner_score = row.get('kw_beginner_keywords', 0)\n",
    "            advanced_score = row.get('kw_advanced_keywords', 0)\n",
    "            \n",
    "            if advanced_score > beginner_score:\n",
    "                return 'advanced'\n",
    "            elif beginner_score > advanced_score:\n",
    "                return 'beginner'\n",
    "            else:\n",
    "                return 'intermediate'  # Default\n",
    "        \n",
    "        result_df['intensity_level'] = result_df.apply(determine_intensity, axis=1)\n",
    "        \n",
    "        # Assess risk\n",
    "        def assess_risk(row):\n",
    "            risky_score = row.get('kw_risky_keywords', 0)\n",
    "            safe_score = row.get('kw_safe_keywords', 0)\n",
    "            movement = row.get('movement_pattern', '')\n",
    "            \n",
    "            # High risk for specific movements\n",
    "            high_risk_patterns = ['hinge', 'rotation']\n",
    "            if movement in high_risk_patterns or risky_score > 0:\n",
    "                return 'high'\n",
    "            elif safe_score > 0 or movement in ['isometric', 'carry']:\n",
    "                return 'low'\n",
    "            else:\n",
    "                return 'medium'  # Default\n",
    "        \n",
    "        result_df['risk_assessment'] = result_df.apply(assess_risk, axis=1)\n",
    "        \n",
    "        print(\"Extracted the following attributes:\\n\" +\n",
    "              f\"- Movement patterns: {result_df['movement_pattern'].nunique()} categories\\n\" +\n",
    "              f\"- Compound exercises: {result_df['is_compound'].sum()} out of {len(result_df)}\\n\" +\n",
    "              f\"- Exercise types: {result_df['exercise_type'].nunique()} categories\\n\" +\n",
    "              f\"- Intensity levels: {result_df['intensity_level'].nunique()} categories\\n\" +\n",
    "              f\"- Risk assessments: {result_df['risk_assessment'].nunique()} categories\")\n",
    "        \n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create text feature extractor and process data\n",
    "if 'cleaned_df' in locals():\n",
    "    text_extractor = TextFeatureExtractor(max_features=200)\n",
    "    \n",
    "    # Extract TF-IDF features\n",
    "    text_df = text_extractor.extract_features(cleaned_df)\n",
    "    \n",
    "    # Extract keyword features\n",
    "    text_kw_df = text_extractor.extract_keyword_features(text_df)\n",
    "    \n",
    "    # Extract exercise attributes\n",
    "    text_attr_df = text_extractor.extract_exercise_attributes(text_kw_df)\n",
    "    \n",
    "    # Save intermediate result\n",
    "    text_attr_df.to_csv(f\"{PROCESSED_DATA_DIR}/text_features.csv\", index=False)\n",
    "    print(f\"Text features saved to {PROCESSED_DATA_DIR}/text_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Analyze Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze extracted text features\n",
    "if 'text_attr_df' in locals():\n",
    "    # Most important TF-IDF features\n",
    "    tfidf_cols = [col for col in text_attr_df.columns if col.startswith('tfidf_')]\n",
    "    feature_means = text_attr_df[tfidf_cols].mean().sort_values(ascending=False)\n",
    "    top_features = feature_means.head(15)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x=top_features.index, y=top_features.values)\n",
    "    plt.title('Most Common TF-IDF Features Across Exercises')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Mean TF-IDF Value')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze movement patterns\n",
    "if 'text_attr_df' in locals():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    pattern_counts = text_attr_df['movement_pattern'].value_counts()\n",
    "    ax = sns.barplot(x=pattern_counts.index, y=pattern_counts.values)\n",
    "    plt.title('Distribution of Exercise Movement Patterns')\n",
    "    plt.xlabel('Movement Pattern')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, count in enumerate(pattern_counts.values):\n",
    "        ax.text(i, count + 2, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze compound vs isolation exercises\n",
    "if 'text_attr_df' in locals():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    compound_counts = text_attr_df['is_compound'].value_counts()\n",
    "    compound_df = pd.DataFrame({'Exercise Type': ['Compound', 'Isolation'], \n",
    "                               'Count': [compound_counts.get(True, 0), compound_counts.get(False, 0)]})\n",
    "    ax = sns.barplot(x='Exercise Type', y='Count', data=compound_df)\n",
    "    plt.title('Compound vs Isolation Exercises')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, count in enumerate(compound_df['Count']):\n",
    "        ax.text(i, count + 5, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze relationships between categories\n",
    "if 'text_attr_df' in locals():\n",
    "    # Relationship between bodypart and movement pattern\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    body_movement = pd.crosstab(text_attr_df['bodypart'], text_attr_df['movement_pattern'])\n",
    "    sns.heatmap(body_movement, annot=True, cmap=\"YlGnBu\", fmt=\"d\", linewidths=.5)\n",
    "    plt.title('Relationship Between Body Part and Movement Pattern')\n",
    "    plt.ylabel('Body Part')\n",
    "    plt.xlabel('Movement Pattern')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pose Feature Extraction\n",
    "\n",
    "Now, let's extract features from exercise images using MediaPipe Pose estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PoseFeatureExtractor:\n",
    "    \"\"\"Extract features from exercise images using MediaPipe\"\"\"\n",
    "    def __init__(self, confidence_threshold=0.5, image_dir=\"data/processed/images\"):\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "        # Initialize MediaPipe pose\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        \n",
    "        # Create directory for saving images\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # Define the landmark indices for different body parts\n",
    "        self.landmark_groups = {\n",
    "            'face': list(range(0, 11)),\n",
    "            'left_arm': [11, 13, 15, 17, 19, 21],\n",
    "            'right_arm': [12, 14, 16, 18, 20, 22], \n",
    "            'left_leg': [23, 25, 27, 29, 31],\n",
    "            'right_leg': [24, 26, 28, 30, 32],\n",
    "            'torso': [11, 12, 23, 24]\n",
    "        }\n",
    "    \n",
    "    def download_and_process_images(self, df, limit=None):\n",
    "        \"\"\"Download and process exercise images using MediaPipe\"\"\"\n",
    "        # Check for image URL column\n",
    "        url_column = None\n",
    "        for col in ['gifurl', 'imageurl']:\n",
    "            if col in df.columns:\n",
    "                url_column = col\n",
    "                break\n",
    "                \n",
    "        if url_column is None:\n",
    "            raise ValueError(\"DataFrame must contain 'gifUrl' or 'imageUrl' column\")\n",
    "        \n",
    "        # Initialize pose detector\n",
    "        pose = self.mp_pose.Pose(\n",
    "            static_image_mode=True, \n",
    "            min_detection_confidence=self.confidence_threshold\n",
    "        )\n",
    "        \n",
    "        # Process images and extract pose landmarks\n",
    "        landmarks_list = []\n",
    "        angles_list = []\n",
    "        heights_list = []\n",
    "        widths_list = []\n",
    "        \n",
    "        # Limit the number of images to process if specified\n",
    "        process_df = df.head(limit) if limit else df\n",
    "        \n",
    "        # Set up progress bar\n",
    "        pbar = tqdm(total=len(process_df), desc=\"Processing images\")\n",
    "        \n",
    "        for i, row in process_df.iterrows():\n",
    "            try:\n",
    "                # Generate a unique ID for each exercise if not present\n",
    "                exercise_id = row.get('id', str(i))\n",
    "                \n",
    "                # Check if image already exists\n",
    "                image_path = f\"{self.image_dir}/{exercise_id}.jpg\"\n",
    "                if os.path.exists(image_path):\n",
    "                    # Load existing image\n",
    "                    image_np = cv2.imread(image_path)\n",
    "                    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "                else:\n",
    "                    # Download image\n",
    "                    response = requests.get(row[url_column])\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    # For GIFs, extract the first frame\n",
    "                    image = Image.open(BytesIO(response.content))\n",
    "                    if hasattr(image, 'n_frames') and image.n_frames > 1:\n",
    "                        image.seek(0)\n",
    "                    \n",
    "                    # Convert to numpy array for OpenCV\n",
    "                    image_np = np.array(image.convert('RGB'))\n",
    "                    \n",
    "                    # Save the first frame as an image\n",
    "                    cv2.imwrite(image_path, cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                # Process with MediaPipe\n",
    "                results = pose.process(image_np)\n",
    "                \n",
    "                if results.pose_landmarks:\n",
    "                    # Extract landmark positions\n",
    "                    landmarks = []\n",
    "                    for landmark in results.pose_landmarks.landmark:\n",
    "                        landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "                    \n",
    "                    # Calculate joint angles\n",
    "                    angles = self._calculate_joint_angles(results.pose_landmarks.landmark)\n",
    "                    \n",
    "                    # Calculate body proportions\n",
    "                    heights, widths = self._calculate_body_proportions(results.pose_landmarks.landmark)\n",
    "                    \n",
    "                    # Draw pose landmarks on the image and save\n",
    "                    annotated_image = image_np.copy()\n",
    "                    self.mp_drawing.draw_landmarks(\n",
    "                        annotated_image,\n",
    "                        results.pose_landmarks,\n",
    "                        self.mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                    )\n",
    "                    \n",
    "                    # Save annotated image\n",
    "                    cv2.imwrite(f\"{self.image_dir}/{exercise_id}_annotated.jpg\", \n",
    "                                cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "                    \n",
    "                else:\n",
    "                    # If no landmarks detected, fill with zeros\n",
    "                    landmarks = [0] * (33 * 4)  # 33 landmarks with x,y,z,visibility\n",
    "                    angles = {}\n",
    "                    heights = {}\n",
    "                    widths = {}\n",
    "                \n",
    "                landmarks_list.append(landmarks)\n",
    "                angles_list.append(angles)\n",
    "                heights_list.append(heights)\n",
    "                widths_list.append(widths)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image for exercise {i}: {e}\")\n",
    "                landmarks_list.append([0] * (33 * 4))\n",
    "                angles_list.append({})\n",
    "                heights_list.append({})\n",
    "                widths_list.append({})\n",
    "            \n",
    "            pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "        # Create feature columns for landmarks\n",
    "        landmark_columns = []\n",
    "        for i in range(33):\n",
    "            for dim in ['x', 'y', 'z', 'vis']:\n",
    "                landmark_columns.append(f\"landmark_{i}_{dim}\")\n",
    "        \n",
    "        landmarks_df = pd.DataFrame(landmarks_list, columns=landmark_columns)\n",
    "        \n",
    "        # Add all feature columns to original DataFrame\n",
    "        result_df = process_df.copy()\n",
    "        for col in landmark_columns:\n",
    "            result_df[col] = landmarks_df[col]\n",
    "        \n",
    "        print(f\"Processed {len(process_df)} images and extracted {len(landmark_columns)} landmark features\")\n",
    "        return result_df\n",
    "    \n",
    "    def _calculate_joint_angles(self, landmarks):\n",
    "        \"\"\"Calculate joint angles from pose landmarks\"\"\"\n",
    "        angles = {}\n",
    "        \n",
    "        # Define key joint pairs for angle calculations\n",
    "        joint_pairs = [\n",
    "            # Left arm angles\n",
    "            ([11, 13, 15], \"left_elbow_angle\"),       # Left shoulder, elbow, wrist\n",
    "            ([13, 11, 23], \"left_shoulder_angle\"),    # Left elbow, shoulder, hip\n",
    "            \n",
    "            # Right arm angles\n",
    "            ([12, 14, 16], \"right_elbow_angle\"),      # Right shoulder, elbow, wrist\n",
    "            ([14, 12, 24], \"right_shoulder_angle\"),   # Right elbow, shoulder, hip\n",
    "            \n",
    "            # Left leg angles\n",
    "            ([23, 25, 27], \"left_knee_angle\"),        # Left hip, knee, ankle\n",
    "            ([25, 23, 11], \"left_hip_angle\"),         # Left knee, hip, shoulder\n",
    "            \n",
    "            # Right leg angles\n",
    "            ([24, 26, 28], \"right_knee_angle\"),       # Right hip, knee, ankle\n",
    "            ([26, 24, 12], \"right_hip_angle\"),        # Right knee, hip, shoulder\n",
    "        ]\n",
    "        \n",
    "        # Convert landmarks to points\n",
    "        points = []\n",
    "        for landmark in landmarks:\n",
    "            points.append([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        \n",
    "        # Calculate angles for each joint pair\n",
    "        for joint_indices, joint_name in joint_pairs:\n",
    "            if all(0 <= idx < len(points) for idx in joint_indices):\n",
    "                # Check visibility\n",
    "                if all(points[idx][3] > self.confidence_threshold for idx in joint_indices):\n",
    "                    # Extract points\n",
    "                    p1 = points[joint_indices[0]][:3]  # Ignore visibility\n",
    "                    p2 = points[joint_indices[1]][:3]\n",
    "                    p3 = points[joint_indices[2]][:3]\n",
    "                    \n",
    "                    # Calculate vectors\n",
    "                    v1 = np.array(p1) - np.array(p2)\n",
    "                    v2 = np.array(p3) - np.array(p2)\n",
    "                    \n",
    "                    # Calculate angle using dot product\n",
    "                    dot_product = np.dot(v1, v2)\n",
    "                    magnitude_product = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "                    \n",
    "                    if magnitude_product > 0:\n",
    "                        cosine_angle = dot_product / magnitude_product\n",
    "                        angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0)) * 180.0 / np.pi\n",
    "                        angles[joint_name] = angle\n",
    "                    else:\n",
    "                        angles[joint_name] = 0\n",
    "                else:\n",
    "                    angles[joint_name] = 0\n",
    "            else:\n",
    "                angles[joint_name] = 0\n",
    "        \n",
    "        return angles\n",
    "    \n",
    "    def _calculate_body_proportions(self, landmarks):\n",
    "        \"\"\"Calculate body group heights and widths\"\"\"\n",
    "        heights = {}\n",
    "        widths = {}\n",
    "        \n",
    "        # Convert landmarks to points\n",
    "        points = []\n",
    "        for landmark in landmarks:\n",
    "            points.append([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        \n",
    "        # Calculate height and width for each landmark group\n",
    "        for group_name, indices in self.landmark_groups.items():\n",
    "            # Filter valid indices with good visibility\n",
    "            valid_indices = [idx for idx in indices if 0 <= idx < len(points) and points[idx][3] > self.confidence_threshold]\n",
    "            \n",
    "            if valid_indices:\n",
    "                # Calculate y-range (height)\n",
    "                y_values = [points[idx][1] for idx in valid_indices]\n",
    "                height = max(y_values) - min(y_values)\n",
    "                heights[group_name] = height\n",
    "                \n",
    "                # Calculate x-range (width)\n",
    "                x_values = [points[idx][0] for idx in valid_indices]\n",
    "                width = max(x_values) - min(x_values)\n",
    "                widths[group_name] = width\n",
    "            else:\n",
    "                heights[group_name] = 0\n",
    "                widths[group_name] = 0\n",
    "        \n",
    "        return heights, widths\n",
    "    \n",
    "    def extract_pose_features(self, df):\n",
    "        \"\"\"Extract derived pose features\"\"\"\n",
    "        # Check if DataFrame has landmark columns\n",
    "        landmark_cols = [col for col in df.columns if col.startswith('landmark_')]\n",
    "        if not landmark_cols:\n",
    "            raise ValueError(\"DataFrame must contain landmark columns. Run download_and_process_images first.\")\n",
    "        \n",
    "        result_df = df.copy()\n",
    "        \n",
    "        print(\"Extracting derived pose features...\")\n",
    "        \n",
    "        # Classify exercise position (standing, seated, etc.)\n",
    "        def classify_position(row):\n",
    "            try:\n",
    "                # Get shoulder landmarks (left and right)\n",
    "                shoulder_y_left = row.get('landmark_11_y', 0)\n",
    "                shoulder_y_right = row.get('landmark_12_y', 0)\n",
    "                shoulder_y = (shoulder_y_left + shoulder_y_right) / 2 if shoulder_y_left > 0 and shoulder_y_right > 0 else 0\n",
    "                \n",
    "                # Get hip landmarks (left and right)\n",
    "                hip_y_left = row.get('landmark_23_y', 0)\n",
    "                hip_y_right = row.get('landmark_24_y', 0)\n",
    "                hip_y = (hip_y_left + hip_y_right) / 2 if hip_y_left > 0 and hip_y_right > 0 else 0\n",
    "                \n",
    "                # Get ankle landmarks (left and right)\n",
    "                ankle_y_left = row.get('landmark_27_y', 0)\n",
    "                ankle_y_right = row.get('landmark_28_y', 0)\n",
    "                ankle_y = (ankle_y_left + ankle_y_right) / 2 if ankle_y_left > 0 and ankle_y_right > 0 else 0\n",
    "                \n",
    "                # Skip if essential landmarks are missing\n",
    "                if shoulder_y == 0 or hip_y == 0 or ankle_y == 0:\n",
    "                    return 'unknown'\n",
    "                \n",
    "                # Detect position based on relationships between landmarks\n",
    "                # Check if ankles are at similar y-position as hips (seated)\n",
    "                ankle_hip_diff = abs(ankle_y - hip_y)\n",
    "                \n",
    "                if ankle_hip_diff < 0.1:  # Small difference indicates seated\n",
    "                    return 'seated'\n",
    "                elif shoulder_y < hip_y and hip_y < ankle_y:  # Vertical alignment\n",
    "                    return 'standing'\n",
    "                elif shoulder_y > hip_y and hip_y > ankle_y:  # Inverted\n",
    "                    return 'inverted'\n",
    "                elif abs(shoulder_y - hip_y) < 0.1:  # Horizontal alignment\n",
    "                    # Check if shoulders are above hips (prone) or below (supine)\n",
    "                    if shoulder_y < ankle_y:\n",
    "                        return 'prone'  # Face down\n",
    "                    else:\n",
    "                        return 'supine'  # Face up\n",
    "                else:\n",
    "                    return 'other'\n",
    "            except:\n",
    "                return 'unknown'\n",
    "        \n",
    "        result_df['pose_position'] = result_df.apply(classify_position, axis=1)\n",
    "        \n",
    "        # Extract dominant movement plane (sagittal, frontal, transverse)\n",
    "        def extract_movement_plane(row):\n",
    "            try:\n",
    "                # Get shoulder width\n",
    "                left_shoulder_x = row.get('landmark_11_x', 0)\n",
    "                right_shoulder_x = row.get('landmark_12_x', 0)\n",
    "                shoulder_width = abs(right_shoulder_x - left_shoulder_x) if left_shoulder_x > 0 and right_shoulder_x > 0 else 0\n",
    "                \n",
    "                # Get hip width\n",
    "                left_hip_x = row.get('landmark_23_x', 0)\n",
    "                right_hip_x = row.get('landmark_24_x', 0)\n",
    "                hip_width = abs(right_hip_x - left_hip_x) if left_hip_x > 0 and right_hip_x > 0 else 0\n",
    "                \n",
    "                # Get arm positions\n",
    "                left_shoulder_z = row.get('landmark_11_z', 0)\n",
    "                left_elbow_z = row.get('landmark_13_z', 0)\n",
    "                left_wrist_z = row.get('landmark_15_z', 0)\n",
    "                \n",
    "                right_shoulder_z = row.get('landmark_12_z', 0)\n",
    "                right_elbow_z = row.get('landmark_14_z', 0)\n",
    "                right_wrist_z = row.get('landmark_16_z', 0)\n",
    "                \n",
    "                # Skip if essential landmarks are missing\n",
    "                if shoulder_width == 0 or hip_width == 0:\n",
    "                    return 'unknown'\n",
    "                \n",
    "                # Calculate width ratio (shoulder to hip)\n",
    "                width_ratio = shoulder_width / hip_width if hip_width > 0 else 1\n",
    "                \n",
    "                # Calculate z-depth of limbs\n",
    "                z_variation = np.std([left_shoulder_z, left_elbow_z, left_wrist_z, \n",
    "                                      right_shoulder_z, right_elbow_z, right_wrist_z])\n",
    "                \n",
    "                # Determine plane based on these measures\n",
    "                if z_variation > 0.1:  # High depth variation\n",
    "                    return 'sagittal'  # Forward/backward movement\n",
    "                elif abs(width_ratio - 1) > 0.2:  # Width difference\n",
    "                    return 'frontal'  # Side-to-side movement\n",
    "                else:\n",
    "                    return 'transverse'  # Rotational movement\n",
    "            except:\n",
    "                return 'unknown'\n",
    "        \n",
    "        result_df['pose_movement_plane'] = result_df.apply(extract_movement_plane, axis=1)\n",
    "        \n",
    "        # Calculate symmetry scores\n",
    "        def calculate_body_symmetry(row):\n",
    "            try:\n",
    "                # Compare left and right side landmarks\n",
    "                pairs = [\n",
    "                    # Shoulders\n",
    "                    ('landmark_11_y', 'landmark_12_y'),\n",
    "                    # Elbows\n",
    "                    ('landmark_13_y', 'landmark_14_y'),\n",
    "                    # Wrists\n",
    "                    ('landmark_15_y', 'landmark_16_y'),\n",
    "                    # Hips\n",
    "                    ('landmark_23_y', 'landmark_24_y'),\n",
    "                    # Knees\n",
    "                    ('landmark_25_y', 'landmark_26_y'),\n",
    "                    # Ankles\n",
    "                    ('landmark_27_y', 'landmark_28_y')\n",
    "                ]\n",
    "                \n",
    "                differences = []\n",
    "                for left, right in pairs:\n",
    "                    left_val = row.get(left, 0)\n",
    "                    right_val = row.get(right, 0)\n",
    "                    if left_val > 0 and right_val > 0:\n",
    "                        differences.append(abs(left_val - right_val))\n",
    "                \n",
    "                if differences:\n",
    "                    # Calculate symmetry score (0-1, higher is more symmetric)\n",
    "                    avg_diff = sum(differences) / len(differences)\n",
    "                    symmetry = max(0, 1 - (avg_diff * 10))  # Scale difference for better range\n",
    "                    return min(symmetry, 1.0)  # Cap at 1.0\n",
    "                else:\n",
    "                    return 0.5  # Default\n",
    "            except:\n",
    "                return 0.5  # Default\n",
    "        \n",
    "        result_df['pose_symmetry'] = result_df.apply(calculate_body_symmetry, axis=1)\n",
    "        \n",
    "        print(f\"Extracted pose features:\\n\" +\n",
    "              f\"- Positions: {result_df['pose_position'].value_counts().to_dict()}\\n\" +\n",
    "              f\"- Movement planes: {result_df['pose_movement_plane'].value_counts().to_dict()}\\n\" +\n",
    "              f\"- Average symmetry score: {result_df['pose_symmetry'].mean():.2f}\")\n",
    "        \n",
    "        return result_df